{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc27e082-f3d3-4370-b0b5-bf50681651e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[LightGBM] [Info] Number of positive: 458, number of negative: 470\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8829\n",
      "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 114\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.493534 -> initscore=-0.025864\n",
      "[LightGBM] [Info] Start training from score -0.025864\n",
      "Ensemble Model Accuracy: 0.6982758620689655\n",
      "Ensemble Model Precision: 0.6982758620689655\n",
      "Training time: 111.32183194160461 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Loading datasets\n",
    "nations_one = pd.read_csv(\"nations_league_1.csv\", index_col=0)\n",
    "nations_two = pd.read_csv(\"nations_league_2.csv\", index_col=0)\n",
    "world_cup = pd.read_csv(\"world_cup.csv\", index_col=0)\n",
    "euro_qual = pd.read_csv(\"euro_qual.csv\", index_col=0)\n",
    "euro_2022 = pd.read_csv(\"euro_2022.csv\", index_col=0)\n",
    "\n",
    "# Function to replace abbreviations with full country names\n",
    "def remove_abbreviation(opponent):\n",
    "    return opponent.split(' ', 1)[1]\n",
    "\n",
    "# Combining all df into one combined df, cleaning up data \n",
    "combined = pd.concat([nations_one, nations_two, world_cup, euro_qual, euro_2022])\n",
    "combined['Opponent'] = combined['Opponent'].apply(remove_abbreviation)\n",
    "combined = combined[combined['Comp'] != 'Friendlies (M)']\n",
    "\n",
    "# Function to adjust rows where the match went to overtime and winner was determined by penalty shoot-out\n",
    "def adjust_result(row):\n",
    "    gf = str(row['GF'])\n",
    "    ga = str(row['GA'])\n",
    "    \n",
    "    if re.search(r'\\(\\d+\\)', gf) and re.search(r'\\(\\d+\\)', ga):\n",
    "        gf_shootout = int(re.search(r'\\((\\d+)\\)', gf).group(1))\n",
    "        ga_shootout = int(re.search(r'\\((\\d+)\\)', ga).group(1))\n",
    "        \n",
    "        if gf_shootout > ga_shootout:\n",
    "            return 'W'\n",
    "        elif gf_shootout < ga_shootout:\n",
    "            return 'L'\n",
    "        else:\n",
    "            return row['Result']\n",
    "    else:\n",
    "        return row['Result']\n",
    "\n",
    "combined['GF'] = combined['GF'].astype(str)\n",
    "combined['GA'] = combined['GA'].astype(str)\n",
    "combined['Result'] = combined.apply(adjust_result, axis=1)\n",
    "\n",
    "# Function to create weighted average for goals for and goals against for matches where winner was determined by penalty shootout\n",
    "def adjust_goals(goals):\n",
    "    goals = str(goals)\n",
    "    if re.search(r'\\(\\d+\\)', goals):\n",
    "        regular_goals = int(re.search(r'^\\d+', goals).group())\n",
    "        shootout_goals = int(re.search(r'\\((\\d+)\\)', goals).group(1))\n",
    "        adjusted_goals = (regular_goals + shootout_goals) / 2\n",
    "        return adjusted_goals\n",
    "    else:\n",
    "        return float(goals)\n",
    "\n",
    "combined['GF'] = combined['GF'].apply(adjust_goals)\n",
    "combined['GA'] = combined['GA'].apply(adjust_goals)\n",
    "\n",
    "combined.columns = combined.columns.str.lower()\n",
    "combined = combined.sort_values(by=\"date\")\n",
    "\n",
    "venue_mapping = {'Home': 1, 'Away': 2, 'Neutral': 3}\n",
    "combined['venue_num'] = combined['venue'].map(venue_mapping).astype(int)\n",
    "\n",
    "# Convert target values to binary (0 for loss, 1 for win)\n",
    "result_mapping = {'L': 0, 'D': 0, 'W': 1}\n",
    "combined = combined.dropna(subset=['result'])\n",
    "combined['target'] = combined['result'].map(result_mapping).astype(int)\n",
    "combined = combined.dropna(subset=['saves'])\n",
    "combined['saves'] = combined['saves'].astype(int)\n",
    "combined = combined.drop(columns=['xg', 'xga'])\n",
    "\n",
    "# Function to create rolling avg for stats\n",
    "def rolling_avg(group, cols, new_cols):\n",
    "    group = group.sort_values(\"date\")\n",
    "    rolling_stats = group[cols].rolling(3, closed='left').mean()\n",
    "    group[new_cols] = rolling_stats\n",
    "    group = group.dropna(subset=new_cols)\n",
    "    return group\n",
    "\n",
    "cols = [\"gf\", \"ga\", \"sh\", \"sot\", \"pk\", \"pkatt\", \"saves\", \"cs\"]\n",
    "new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "\n",
    "combined_rolling = combined.groupby('nation').apply(lambda x: rolling_avg(x, cols, new_cols))\n",
    "combined_rolling = combined_rolling.droplevel('nation')\n",
    "combined_rolling = combined_rolling.sort_values(by=\"date\")\n",
    "\n",
    "# Adding additional feature columns\n",
    "combined_rolling[\"venue_code\"] = combined_rolling[\"venue\"].astype(\"category\").cat.codes\n",
    "combined_rolling[\"opp_code\"] = combined_rolling[\"opponent\"].astype(\"category\").cat.codes\n",
    "combined_rolling[\"hour\"] = combined_rolling[\"time\"].str.replace(\":.+\", \"\", regex=True).astype(int)\n",
    "combined_rolling[\"date\"] = pd.to_datetime(combined_rolling[\"date\"])\n",
    "combined_rolling[\"day_code\"] = combined_rolling[\"date\"].dt.dayofweek\n",
    "\n",
    "# Define initial features\n",
    "initial_features = ['gf_rolling', 'ga_rolling', 'sh_rolling', 'sot_rolling', 'pk_rolling', 'pkatt_rolling', 'saves_rolling', 'cs_rolling',\n",
    "                    'venue_code', 'opp_code', 'hour', 'day_code']\n",
    "\n",
    "# Create interaction features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "poly_features = poly.fit_transform(combined_rolling[initial_features])\n",
    "poly_feature_names = poly.get_feature_names_out(initial_features)\n",
    "poly_df = pd.DataFrame(poly_features, columns=poly_feature_names, index=combined_rolling.index)\n",
    "combined_rolling = pd.concat([combined_rolling, poly_df], axis=1)\n",
    "\n",
    "# Define the final features to use for each team\n",
    "features = initial_features + list(poly_feature_names)\n",
    "\n",
    "# Splitting the dataset into train and test set (80-20 split for better generalization)\n",
    "X = combined_rolling[features]\n",
    "y = combined_rolling['target']\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter tuning for RandomForest using RandomizedSearchCV\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                                      param_distributions=rf_param_grid,\n",
    "                                      scoring='accuracy',\n",
    "                                      n_iter=10,\n",
    "                                      n_jobs=-1,\n",
    "                                      cv=3,\n",
    "                                      verbose=2,\n",
    "                                      random_state=42)\n",
    "\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "best_rf_params = rf_random_search.best_params_\n",
    "\n",
    "# Hyperparameter tuning for Logistic Regression using RandomizedSearchCV\n",
    "lr_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "lr_random_search = RandomizedSearchCV(estimator=LogisticRegression(random_state=42),\n",
    "                                      param_distributions=lr_param_grid,\n",
    "                                      scoring='accuracy',\n",
    "                                      n_iter=10,\n",
    "                                      n_jobs=-1,\n",
    "                                      cv=3,\n",
    "                                      verbose=2,\n",
    "                                      random_state=42)\n",
    "\n",
    "lr_random_search.fit(X_train, y_train)\n",
    "best_lr_params = lr_random_search.best_params_\n",
    "\n",
    "# Hyperparameter tuning for XGBoost using RandomizedSearchCV\n",
    "xgb_param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "xgb_random_search = RandomizedSearchCV(estimator=xgb.XGBClassifier(objective='binary:hinge'),\n",
    "                                       param_distributions=xgb_param_grid,\n",
    "                                       scoring='accuracy',\n",
    "                                       n_iter=10,\n",
    "                                       n_jobs=-1,\n",
    "                                       cv=3,\n",
    "                                       verbose=2,\n",
    "                                       random_state=42)\n",
    "\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "best_xgb_params = xgb_random_search.best_params_\n",
    "\n",
    "# Hyperparameter tuning for CatBoost using RandomizedSearchCV\n",
    "cb_param_grid = {\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "    'iterations': [100, 200, 300, 500]\n",
    "}\n",
    "\n",
    "cb_random_search = RandomizedSearchCV(estimator=cb.CatBoostClassifier(verbose=0, random_state=42),\n",
    "                                      param_distributions=cb_param_grid,\n",
    "                                      scoring='accuracy',\n",
    "                                      n_iter=10,\n",
    "                                      n_jobs=-1,\n",
    "                                      cv=3,\n",
    "                                      verbose=2,\n",
    "                                      random_state=42)\n",
    "\n",
    "cb_random_search.fit(X_train, y_train)\n",
    "best_cb_params = cb_random_search.best_params_\n",
    "\n",
    "# Train models with best hyperparameters\n",
    "log_clf = LogisticRegression(**best_lr_params, random_state=42)\n",
    "rf_clf = RandomForestClassifier(**best_rf_params, random_state=42)\n",
    "xgb_clf = xgb.XGBClassifier(**best_xgb_params, objective='binary:hinge')\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "lgb_clf = lgb.LGBMClassifier(random_state=42)\n",
    "cb_clf = cb.CatBoostClassifier(**best_cb_params, verbose=0, random_state=42)\n",
    "\n",
    "# Ensemble with VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', log_clf),\n",
    "    ('rf', rf_clf),\n",
    "    ('xgb', xgb_clf),\n",
    "    ('gb', gb_clf),\n",
    "    ('lgb', lgb_clf),\n",
    "    ('cb', cb_clf)\n",
    "], voting='soft')  # Use 'soft' voting\n",
    "\n",
    "start_time = time.time()\n",
    "voting_clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and precision for ensemble\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "precision_voting = precision_score(y_test, y_pred_voting, average='weighted')\n",
    "\n",
    "print(f'Ensemble Model Accuracy: {accuracy_voting}')\n",
    "print(f'Ensemble Model Precision: {precision_voting}')\n",
    "print(f'Training time: {end_time - start_time} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
